{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LpMCk_T0By59"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio.v3 as imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# sys.path.append(\"FracTAL_ResUNet/)\n",
    "sys.path.append(\"./GitHub/FracTAL_ResUNet/\")\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "# import visdom\n",
    "# sys.path.append('resuneta/') # do we need this repo?\n",
    "# sys.path.append('../../')\n",
    "\n",
    "# from resuneta.bound_dist import get_distance, get_boundary\n",
    "\n",
    "# from bound_dist import get_distance, get_boundary\n",
    "# from loss import TanimotoDualLoss\n",
    "# from resuneta.models.resunet_d6_causal_mtskcolor_ddist import *\n",
    "from models.semanticsegmentation.FracTAL_ResUNet import FracTAL_ResUNet_cmtsk\n",
    "\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your custom PyTorch dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_directory, label_directory, fold='train', image_names=None,\n",
    "                 label_names=None, classes=[255], image_suffix='.jpeg', label_suffix='.png',\n",
    "                 boundary_kernel_size=(3,3)):\n",
    "        self.image_directory = image_directory\n",
    "        self.label_directory = label_directory\n",
    "        self.fold = fold\n",
    "        self.image_suffix = image_suffix\n",
    "        self.label_suffix = label_suffix\n",
    "        self.classes = classes\n",
    "\n",
    "        if image_names is None:\n",
    "            image_names = os.listdir(image_directory)\n",
    "            self.image_names = [x.split('.')[0] for x in image_names]\n",
    "        else:\n",
    "            self.image_names = image_names\n",
    "\n",
    "        if label_names is None:\n",
    "            self.label_names = image_names\n",
    "        else:\n",
    "            self.label_names = label_names\n",
    "\n",
    "        self.boundary_kernel_size = boundary_kernel_size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = np.zeros((256, 256, 3))\n",
    "        image_path = os.path.join(self.image_directory,\n",
    "                                  str(self.image_names[item]) + self.image_suffix)\n",
    "        image_temp = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        nrow, ncol, nchannels = image_temp.shape\n",
    "        image[:nrow, :ncol] = image_temp[:256, :256]\n",
    "\n",
    "        extent_path = os.path.join(self.label_directory,\n",
    "                                   str(self.label_names[item % len(self.label_names)]) + self.label_suffix)\n",
    "        extent_mask = np.zeros((256, 256))\n",
    "        extent_image = imageio.imread(extent_path)\n",
    "        nrow, ncol = extent_image.shape\n",
    "        extent_image = np.array(np.isin(extent_image, self.classes), dtype=np.uint8)\n",
    "        extent_mask[:nrow, :ncol] = extent_image[:256, :256]\n",
    "\n",
    "        if self.fold == 'train':\n",
    "            # brightness augmentation\n",
    "            image = np.minimum(np.random.uniform(low=0.8, high=1.25) * image, 255)\n",
    "\n",
    "            # rotation augmentation\n",
    "            k = np.random.randint(low=0, high=4)\n",
    "            image = np.rot90(image, k, axes=(0, 1))\n",
    "            extent_mask = np.rot90(extent_mask, k, axes=(0, 1))\n",
    "\n",
    "            # flip augmentation\n",
    "            if np.random.uniform() > 0.5:\n",
    "                image = np.flip(image, axis=0)\n",
    "                extent_mask = np.flip(extent_mask, axis=0)\n",
    "            if np.random.uniform() > 0.5:\n",
    "                image = np.flip(image, axis=1)\n",
    "                extent_mask = np.flip(extent_mask, axis=1)\n",
    "\n",
    "        image = image.astype(np.uint8)\n",
    "        boundary_mask = get_boundary(extent_mask, kernel_size=self.boundary_kernel_size)\n",
    "        distance_mask = get_distance(extent_mask)\n",
    "        image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        image = torch.from_numpy(np.moveaxis(image, -1, 0))\n",
    "        image_hsv = torch.from_numpy(np.moveaxis(image_hsv, -1, 0)) / 255.\n",
    "        extent_mask = torch.unsqueeze(torch.from_numpy(extent_mask), 0)\n",
    "        boundary_mask = torch.unsqueeze(torch.from_numpy(boundary_mask), 0)\n",
    "        distance_mask = torch.unsqueeze(torch.from_numpy(distance_mask), 0)\n",
    "\n",
    "        return image, extent_mask, boundary_mask, distance_mask, image_hsv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "# You can then create an instance of your CustomDataset and use it with a PyTorch DataLoader for training.\n",
    "\n",
    "class PlanetDatasetWithClasses(Dataset):\n",
    "    def __init__(self, image_directory, label_directory, fold='train', image_names=None,\n",
    "                 label_names=None, classes=[255], image_suffix='.jpeg', label_suffix='.png',\n",
    "                 boundary_kernel_size=(3, 3)):\n",
    "        self.image_directory = image_directory\n",
    "        self.label_directory = label_directory\n",
    "        self.fold = fold\n",
    "        self.image_suffix = image_suffix\n",
    "        self.label_suffix = label_suffix\n",
    "        self.classes = classes\n",
    "\n",
    "        if image_names is None:\n",
    "            image_names = os.listdir(image_directory)\n",
    "            self.image_names = [x.split('.')[0] for x in image_names]\n",
    "        else:\n",
    "            self.image_names = image_names\n",
    "\n",
    "        if label_names is None:\n",
    "            self.label_names = image_names\n",
    "        else:\n",
    "            self.label_names = label_names\n",
    "\n",
    "        self.boundary_kernel_size = boundary_kernel_size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = np.zeros((256, 256, 3))\n",
    "        image_path = os.path.join(self.image_directory,\n",
    "                                  str(self.image_names[item]) + self.image_suffix)\n",
    "        image_temp = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        nrow, ncol, nchannels = image_temp.shape\n",
    "        image[:nrow, :ncol] = image_temp[:256, :256]\n",
    "\n",
    "        extent_path = os.path.join(self.label_directory,\n",
    "                                   str(self.label_names[item % len(self.label_names)]) + self.label_suffix)\n",
    "        extent_mask = np.zeros((256, 256))\n",
    "        extent_image = imageio.imread(extent_path)\n",
    "        nrow, ncol = extent_image.shape\n",
    "        extent_image = np.array(np.isin(extent_image, self.classes), dtype=np.uint8)\n",
    "        extent_mask[:nrow, :ncol] = extent_image[:256, :256]\n",
    "\n",
    "        if self.fold == 'train':\n",
    "            # brightness augmentation\n",
    "            image = np.minimum(np.random.uniform(low=0.8, high=1.25) * image, 255)\n",
    "\n",
    "            # rotation augmentation\n",
    "            k = np.random.randint(low=0, high=4)\n",
    "            image = np.rot90(image, k, axes=(0, 1))\n",
    "            extent_mask = np.rot90(extent_mask, k, axes=(0, 1))\n",
    "\n",
    "            # flip augmentation\n",
    "            if np.random.uniform() > 0.5:\n",
    "                image = np.flip(image, axis=0)\n",
    "                extent_mask = np.flip(extent_mask, axis=0)\n",
    "            if np.random.uniform() > 0.5:\n",
    "                image = np.flip(image, axis=1)\n",
    "                extent_mask = np.flip(extent_mask, axis=1)\n",
    "\n",
    "        image = image.astype(np.uint8)\n",
    "        boundary_mask = get_boundary(extent_mask, kernel_size=self.boundary_kernel_size)\n",
    "        distance_mask = get_distance(extent_mask)\n",
    "        image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        image = F.to_tensor(np.moveaxis(image, -1, 0))\n",
    "        image_hsv = F.to_tensor(np.moveaxis(image_hsv, -1, 0)) / 255.\n",
    "        extent_mask = torch.unsqueeze(torch.tensor(extent_mask), 0)\n",
    "        boundary_mask = torch.unsqueeze(torch.tensor(boundary_mask), 0)\n",
    "        distance_mask = torch.unsqueeze(torch.tensor(distance_mask), 0)\n",
    "\n",
    "        return image, extent_mask, boundary_mask, distance_mask, image_hsv\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "class PlanetDatasetWithClassesFullPathsMasked(Dataset):\n",
    "\n",
    "    def __init__(self, fold='train', image_names=None, label_names=None, classes=[1],\n",
    "                 noncrop_classes=[2], boundary_kernel_size=(3, 3)):\n",
    "\n",
    "        self.fold = fold\n",
    "        self.classes = classes\n",
    "        self.noncrop_classes = noncrop_classes\n",
    "        self.image_names = image_names\n",
    "        self.label_names = label_names\n",
    "        self.boundary_kernel_size = boundary_kernel_size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = np.zeros((256, 256, 3))\n",
    "        image_path = self.image_names[item]\n",
    "        image_temp = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "        nrow, ncol, nchannels = image_temp.shape\n",
    "\n",
    "        extent_path = self.label_names[item]\n",
    "        extent_mask = np.zeros((256, 256))\n",
    "        extent_original = imageio.imread(extent_path)\n",
    "        nrow, ncol = extent_original.shape\n",
    "        extent_image = np.array(np.isin(extent_original, self.classes), dtype=np.uint8)\n",
    "\n",
    "        topleft_x, topleft_y = 0, 0\n",
    "        if nrow > 256:\n",
    "            topleft_x = np.random.choice(np.arange(0, nrow-256))\n",
    "        if ncol > 256:\n",
    "            topleft_y = np.random.choice(np.arange(0, ncol-256))\n",
    "\n",
    "        image[:nrow, :ncol] = image_temp[topleft_x:topleft_x+256, topleft_y:topleft_y+256]\n",
    "        extent_mask[:nrow, :ncol] = extent_image[topleft_x:topleft_x+256, topleft_y:topleft_y+256]\n",
    "\n",
    "        noncrop_mask = np.zeros((256, 256))\n",
    "        noncrop_image = np.array(np.isin(extent_original, self.noncrop_classes), dtype=np.uint8)\n",
    "        noncrop_mask[:nrow, :ncol] = noncrop_image[topleft_x:topleft_x+256, topleft_y:topleft_y+256]\n",
    "\n",
    "        if self.fold == 'train':\n",
    "            # brightness augmentation\n",
    "            image = np.minimum(np.random.uniform(low=0.8, high=1.25) * image, 255)\n",
    "\n",
    "            # rotation augmentation\n",
    "            k = np.random.randint(low=0, high=4)\n",
    "            image = np.rot90(image, k, axes=(0,1))\n",
    "            extent_mask = np.rot90(extent_mask, k, axes=(0,1))\n",
    "\n",
    "            # flip augmentation\n",
    "            if np.random.uniform() > 0.5:\n",
    "                image = np.flip(image, axis=0)\n",
    "                extent_mask = np.flip(extent_mask, axis=0)\n",
    "            if np.random.uniform() > 0.5:\n",
    "                image = np.flip(image, axis=1)\n",
    "                extent_mask = np.flip(extent_mask, axis=1)\n",
    "\n",
    "        image = image.astype(np.uint8)\n",
    "        boundary_mask = get_boundary(extent_mask, kernel_size=self.boundary_kernel_size)\n",
    "        distance_mask = get_distance(extent_mask)\n",
    "        image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        # Define label mask\n",
    "        label_mask = np.array((extent_mask + boundary_mask + noncrop_mask) >= 1, dtype=np.float32)\n",
    "\n",
    "        image = F.to_tensor(image)\n",
    "        image_hsv = torch.tensor(image_hsv.transpose(2, 0, 1) / 255.0, dtype=torch.float32)\n",
    "        \n",
    "        # Create copies of the numpy arrays to ensure positive strides\n",
    "        extent_mask_copy = extent_mask.copy()\n",
    "        boundary_mask_copy = boundary_mask.copy()\n",
    "        distance_mask_copy = distance_mask.copy()\n",
    "        label_mask_copy = label_mask.copy()\n",
    "\n",
    "        # Now convert the copied numpy arrays to tensors and unsqueeze\n",
    "        extent_mask = torch.unsqueeze(torch.tensor(extent_mask_copy, dtype=torch.float32), 0)\n",
    "        boundary_mask = torch.unsqueeze(torch.tensor(boundary_mask_copy, dtype=torch.float32), 0)\n",
    "        distance_mask = torch.unsqueeze(torch.tensor(distance_mask_copy, dtype=torch.float32), 0)\n",
    "        label_mask = torch.unsqueeze(torch.tensor(label_mask_copy, dtype=torch.float32), 0)\n",
    "        \n",
    "        return image, extent_mask, boundary_mask, distance_mask, image_hsv, label_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "B3Rn2hxfCHKU"
   },
   "outputs": [],
   "source": [
    "def dice_coef(x, y):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        intersection = np.logical_and(x, y)\n",
    "        return 2. * np.sum(intersection) / (np.sum(x) + np.sum(y))\n",
    "    else:\n",
    "        intersection = torch.logical_and(x, y)\n",
    "        return 2. * torch.sum(intersection) / (torch.sum(x) + torch.sum(y))\n",
    "\n",
    "# Commented out Visdom-related function\n",
    "# def visdom_visualize_batch(vis, img, extent, boundary, distance,\n",
    "#                            extent_pred, boundary_pred, distance_pred,\n",
    "#                            hsv, hsv_pred, mask, title=\"Train images\"):\n",
    "\n",
    "#     img, extent, boundary, distance = img.cpu().numpy(), extent.cpu().numpy(), boundary.cpu().numpy(), distance.cpu().numpy()\n",
    "#     extent_pred, boundary_pred = extent_pred.cpu().numpy(), boundary_pred.cpu().numpy()\n",
    "#     distance_pred, hsv, hsv_pred = distance_pred.cpu().numpy(), hsv.cpu().numpy(), hsv_pred.cpu().numpy()\n",
    "#     mask = mask.cpu().numpy()\n",
    "\n",
    "#     # put everything in one window\n",
    "#     batch_size, nchannels, nrows, ncols = img.shape\n",
    "#     padding = 10\n",
    "#     items = [img, hsv, hsv_pred, extent, extent_pred,\n",
    "#              boundary, boundary_pred, distance, distance_pred,\n",
    "#              mask]\n",
    "#     result = np.zeros((3, len(items)*nrows + (len(items)-1)*padding, batch_size*ncols + (batch_size-1)*padding))\n",
    "\n",
    "#     for j, item in enumerate(items):\n",
    "\n",
    "#         if item.shape[1] == 1:\n",
    "#             item = np.tile(item, (1,3,1,1)) * 255.\n",
    "\n",
    "#         if j == 1 or j == 2: # convert HSV to RGB\n",
    "#             item = np.moveaxis(item, 1, -1) * 255.\n",
    "#             for i in range(batch_size):\n",
    "#                 item[i] = cv2.cvtColor(item[i].astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "#             item = np.moveaxis(item, -1, 1)\n",
    "\n",
    "#         for i in range(batch_size):\n",
    "#             result[:, j*(nrows+padding):(j+1)*nrows+j*padding, i*(ncols+padding):(i+1)*ncols+i*padding] = item[i]\n",
    "#     vis.images(result, nrow=1, win=title, opts={'title': title})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kEMnGOn5DIFJ"
   },
   "outputs": [],
   "source": [
    "def get_boundary(mask, kernel_size=(3, 3)):\n",
    "    kernel = np.ones(kernel_size, np.uint8)\n",
    "    dilation = cv2.dilate(mask, kernel, iterations=1)\n",
    "    return dilation - mask\n",
    "\n",
    "def get_distance(mask):\n",
    "    return distance_transform_edt(1 - mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Jj_IvsnXDqTT"
   },
   "outputs": [],
   "source": [
    "class Tanimoto(nn.Module):\n",
    "    def __init__(self, smooth=1.0e-5, axis=(2, 3), weight=None, batch_axis=0):\n",
    "        super(Tanimoto, self).__init__()\n",
    "        self.axis = axis\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, label):\n",
    "        # Evaluate the mean volume of class per batch\n",
    "        Vli = torch.mean(torch.sum(label, dim=self.axis), dim=0)\n",
    "        wli = 1.0 / (Vli**2)  # weighting scheme\n",
    "\n",
    "        # First turn inf elements to zero, then replace that with the maximum weight value\n",
    "        wli = torch.where(torch.isinf(wli), torch.zeros_like(wli), wli)\n",
    "        wli = torch.where(torch.isinf(wli), torch.max(wli) * torch.ones_like(wli), wli)\n",
    "\n",
    "        rl_x_pl = torch.sum(label * preds, dim=self.axis)\n",
    "        # This is sum of squares\n",
    "        l = torch.sum(label * label, dim=self.axis)\n",
    "        r = torch.sum(preds * preds, dim=self.axis)\n",
    "\n",
    "        rl_p_pl = l + r - rl_x_pl\n",
    "\n",
    "        tnmt = (torch.sum(wli * rl_x_pl, dim=1) + self.smooth) / (torch.sum(wli * rl_p_pl, dim=1) + self.smooth)\n",
    "\n",
    "        return tnmt\n",
    "\n",
    "class TanimotoWithDual(nn.Module):\n",
    "    def __init__(self, smooth=1.0e-5, axis=(2, 3), weight=None, batch_axis=0):\n",
    "        super(TanimotoWithDual, self).__init__()\n",
    "        self.tanimoto = Tanimoto(smooth=smooth, axis=axis)\n",
    "\n",
    "    def forward(self, preds, label):\n",
    "        # Measure of overlap\n",
    "        loss1 = self.tanimoto(preds, label)\n",
    "\n",
    "        # Measure of non-overlap as inner product\n",
    "        preds_dual = 1.0 - preds\n",
    "        labels_dual = 1.0 - label\n",
    "        loss2 = self.tanimoto(preds_dual, labels_dual)\n",
    "\n",
    "        return 0.5 * (loss1 + loss2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gAG-3jC_KokQ"
   },
   "outputs": [],
   "source": [
    "class ftnmt_loss(nn.Module):\n",
    "    def __init__(self, depth=5, axis=[1,2,3], smooth=1.0e-5):\n",
    "        super(ftnmt_loss, self).__init__()\n",
    "\n",
    "        assert depth >= 0, ValueError(\"depth must be >= 0, aborting...\")\n",
    "\n",
    "        self.smooth = smooth\n",
    "        self.axis = axis\n",
    "        self.depth = depth\n",
    "\n",
    "        if depth == 0:\n",
    "            self.depth = 1\n",
    "            self.scale = 1.\n",
    "        else:\n",
    "            self.depth = depth\n",
    "            self.scale = 1./depth\n",
    "\n",
    "    def inner_prod(self, prob, label):\n",
    "        prod = prob * label\n",
    "        prod = torch.sum(prod, dim=self.axis)\n",
    "        return prod\n",
    "\n",
    "    def tnmt_base(self, preds, labels):\n",
    "\n",
    "        tpl = self.inner_prod(preds, labels)\n",
    "        tpp = self.inner_prod(preds, preds)\n",
    "        tll = self.inner_prod(labels, labels)\n",
    "\n",
    "        num = tpl + self.smooth\n",
    "        scale = 1./self.depth\n",
    "        denum = 0.0\n",
    "\n",
    "        for d in range(self.depth):\n",
    "            a = 2.**d\n",
    "            b = -(2.*a-1.)\n",
    "\n",
    "            denum = denum + torch.reciprocal(a*(tpp+tll) + b * tpl + self.smooth)\n",
    "\n",
    "        result = num * denum * scale\n",
    "        return torch.mean(result)\n",
    "\n",
    "    def forward(self, preds, labels):\n",
    "\n",
    "        l1 = self.tnmt_base(preds, labels)\n",
    "        l2 = self.tnmt_base(1. - preds, 1. - labels)\n",
    "\n",
    "        result = 0.5 * (l1 + l2)\n",
    "\n",
    "        return 1. - result\n",
    "\n",
    "\n",
    "class ftnmt_loss_masked(nn.Module):\n",
    "    def __init__(self, depth=5, axis=[1,2,3], smooth=1.0e-5):\n",
    "        super(ftnmt_loss_masked, self).__init__()\n",
    "\n",
    "        assert depth >= 0, ValueError(\"depth must be >= 0, aborting...\")\n",
    "\n",
    "        self.smooth = smooth\n",
    "        self.axis = axis\n",
    "        self.depth = depth\n",
    "\n",
    "        if depth == 0:\n",
    "            self.depth = 1\n",
    "            self.scale = 1.\n",
    "        else:\n",
    "            self.depth = depth\n",
    "            self.scale = 1./depth\n",
    "\n",
    "    def inner_prod(self, prob, label):\n",
    "        prod = prob * label\n",
    "        prod = torch.sum(prod, dim=self.axis)\n",
    "        return prod\n",
    "\n",
    "    def tnmt_base(self, preds, labels):\n",
    "\n",
    "        tpl = self.inner_prod(preds, labels)\n",
    "        tpp = self.inner_prod(preds, preds)\n",
    "        tll = self.inner_prod(labels, labels)\n",
    "\n",
    "        num = tpl + self.smooth\n",
    "        scale = 1./self.depth\n",
    "        denum = 0.0\n",
    "\n",
    "        for d in range(self.depth):\n",
    "            a = 2.**d\n",
    "            b = -(2.*a-1.)\n",
    "\n",
    "            denum = denum + torch.reciprocal(a*(tpp+tll) + b * tpl + self.smooth)\n",
    "\n",
    "        result = num * denum * scale\n",
    "        return torch.mean(result)\n",
    "\n",
    "    def forward(self, preds, labels, mask):\n",
    "\n",
    "        preds = preds * mask\n",
    "\n",
    "        preds_dual = 1. - preds\n",
    "        labels_dual = 1. - labels\n",
    "        preds_dual = preds_dual * mask\n",
    "        labels_dual = labels_dual * mask\n",
    "\n",
    "        l1 = self.tnmt_base(preds, labels)\n",
    "        l2 = self.tnmt_base(preds_dual, labels_dual)\n",
    "\n",
    "        result = 0.5 * (l1 + l2)\n",
    "\n",
    "        return 1. - result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AkRYsfGTIuNf"
   },
   "outputs": [],
   "source": [
    "def dice_coef(x, y):\n",
    "    if type(x).__module__ == 'numpy':\n",
    "        intersection = np.logical_and(x, y)\n",
    "        return 2. * np.sum(intersection) / (np.sum(x) + np.sum(y))\n",
    "    else:\n",
    "        intersection = mx.ndarray.op.broadcast_logical_and(x, y)\n",
    "        return 2. * mx.nd.sum(intersection) / (mx.nd.sum(x) + mx.nd.sum(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "JkOaRdy5CYjf",
    "outputId": "143311fb-ae4f-4310-e8d5-0317dcdb75ee"
   },
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train_model(train_dataloader, model, tanimoto_dual, optimizer, epoch, args):\n",
    "    model.train()\n",
    "\n",
    "    # Initialize metrics\n",
    "    cumulative_loss = 0\n",
    "    accuracy = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    dice = 0\n",
    "\n",
    "    device = args['device']\n",
    "\n",
    "    for batch_i, (img, extent, boundary, distance, hsv, mask) in enumerate(\n",
    "        tqdm(train_dataloader, desc='Training epoch {}'.format(epoch))):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        print(img.shape)\n",
    "        img = img.to(device)\n",
    "        extent = extent.to(device)\n",
    "        boundary = boundary.to(device)\n",
    "        distance = distance.to(device)\n",
    "        hsv = hsv.to(device)\n",
    "        mask = mask.to(device)\n",
    "        nonmask = torch.ones(extent.shape).to(device)\n",
    "\n",
    "        # logits, bound, dist, convc = model(img)\n",
    "        logits, bound, dist = model(img)\n",
    "\n",
    "        # Multi-task loss\n",
    "        # TODO: wrap this in a custom loss function / class\n",
    "        loss_extent = tanimoto_dual(logits, extent, mask)\n",
    "        loss_boundary = tanimoto_dual(bound, boundary, mask)\n",
    "        loss_distance = tanimoto_dual(dist, distance, mask)\n",
    "\n",
    "        loss = 0.33 * (loss_extent + loss_boundary + loss_distance)  # + loss_hsv)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "        # Update metrics based on every batch\n",
    "        logits_reshaped = logits.view(logits.shape[0], -1)\n",
    "        extent_reshaped = extent.view(extent.shape[0], -1)\n",
    "        mask_reshaped = mask.view(mask.shape[0], -1)\n",
    "\n",
    "        nonmask_idx = torch.nonzero(mask_reshaped, as_tuple=True)\n",
    "        nonmask_idx = torch.stack(nonmask_idx).to(device)\n",
    "        logits_masked = torch.gather(logits_reshaped, 1, nonmask_idx)\n",
    "        extent_masked = torch.gather(extent_reshaped, 1, nonmask_idx)\n",
    "\n",
    "        # nonmask_idx = torch.nonzero(mask_reshaped).to(device)\n",
    "        # logits_masked = logits_reshaped.gather(1, nonmask_idx)\n",
    "        # extent_masked = extent_reshaped.gather(1, nonmask_idx)\n",
    "\n",
    "        # logits_reshaped = logits.reshape((logits.shape[0], -1))\n",
    "        # extent_reshaped = extent.reshape((extent.shape[0], -1))\n",
    "        # mask_reshaped = mask.reshape((mask.shape[0], -1))\n",
    "\n",
    "        # nonmask_idx = mx.np.nonzero(mask_reshaped.as_np_ndarray())\n",
    "        # nonmask_idx = mx.np.stack(nonmask_idx).as_nd_ndarray().as_in_context(ctx)\n",
    "        # logits_masked = mx.nd.gather_nd(logits_reshaped, nonmask_idx)\n",
    "        # extent_masked = mx.nd.gather_nd(extent_reshaped, nonmask_idx)\n",
    "\n",
    "        # Accuracy\n",
    "        extent_predicted_classes = (logits_masked - 0.5).ceil()\n",
    "        accuracy += (extent_predicted_classes == extent_masked).sum().item()\n",
    "\n",
    "        # # F1 score\n",
    "        # probabilities = torch.cat([(1 - logits_masked), logits_masked], dim=1)\n",
    "        # f1 += f1_score(extent_masked.cpu().detach().numpy(), \n",
    "                       \n",
    "        #                probabilities.cpu().numpy())\n",
    "\n",
    "        # # MCC metric\n",
    "        # # mcc += matthews_corrcoef(extent_masked.cpu().numpy(), probabilities.cpu().numpy())\n",
    "        # mcc = 0\n",
    "        # # Dice score\n",
    "        # dice += dice_coef(extent_masked, extent_predicted_classes)\n",
    "\n",
    "        # TEMPORARY to make visdom work\n",
    "#         convc = hsv\n",
    "#         if batch_i % args['visdom_every'] == 0:\n",
    "#             # visdom_visualize_batch(args['visdom'], img, extent, boundary, distance,\n",
    "#             #                        logits, bound, dist, hsv, convc, mask)\n",
    "#             pass\n",
    "\n",
    "    return cumulative_loss, accuracy, f1, mcc, dice\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_model(val_dataloader, model, tanimoto_dual, epoch, args):\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize metrics\n",
    "    cumulative_loss = 0\n",
    "    accuracy = 0\n",
    "    f1 = 0\n",
    "    mcc = 0\n",
    "    dice = 0\n",
    "\n",
    "    device = args['device']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_i, (img, extent, boundary, distance, hsv, mask) in enumerate(\n",
    "            tqdm(val_dataloader, desc='Validation epoch {}'.format(epoch))):\n",
    "\n",
    "            img = img.to(device)\n",
    "            extent = extent.to(device)\n",
    "            boundary = boundary.to(device)\n",
    "            distance = distance.to(device)\n",
    "            hsv = hsv.to(device)\n",
    "            mask = mask.to(device)\n",
    "            nonmask = torch.ones(extent.shape).to(device)\n",
    "\n",
    "            # logits, bound, dist, convc = model(img)\n",
    "            logits, bound, dist = model(img)\n",
    "\n",
    "            # Multi-task loss\n",
    "            # TODO: wrap this in a custom loss function / class\n",
    "            loss_extent = tanimoto_dual(logits, extent, mask)\n",
    "            loss_boundary = tanimoto_dual(bound, boundary, mask)\n",
    "            loss_distance = tanimoto_dual(dist, distance, mask)\n",
    "\n",
    "            loss = 0.33 * (loss_extent + loss_boundary + loss_distance)  # + loss_hsv)\n",
    "\n",
    "            cumulative_loss += loss.item()\n",
    "\n",
    "            # Update metrics based on every batch\n",
    "            logits_reshaped = logits.view(logits.shape[0], -1)\n",
    "            extent_reshaped = extent.view(extent.shape[0], -1)\n",
    "            mask_reshaped = mask.view(mask.shape[0], -1)\n",
    "\n",
    "            nonmask_idx = torch.nonzero(mask_reshaped, as_tuple=True)\n",
    "            nonmask_idx = torch.stack(nonmask_idx).to(device)\n",
    "            logits_masked = torch.gather(logits_reshaped, 1, nonmask_idx)\n",
    "            extent_masked = torch.gather(extent_reshaped, 1, nonmask_idx)\n",
    "\n",
    "            # Accuracy\n",
    "            extent_predicted_classes = (logits_masked - 0.5).ceil()\n",
    "            accuracy += (extent_predicted_classes == extent_masked).sum().item()\n",
    "\n",
    "            # # F1 score\n",
    "            # probabilities = torch.cat([(1 - logits_masked), logits_masked], dim=1)\n",
    "            # f1 += f1_score(extent_masked.cpu().numpy(), probabilities.cpu().numpy())\n",
    "\n",
    "            # # MCC metric\n",
    "            # # mcc += matthews_corrcoef(extent_masked.cpu().numpy(), probabilities.cpu().numpy())\n",
    "            # mcc = 0\n",
    "            # # Dice score\n",
    "            # dice += dice_coef(extent_masked, extent_predicted_classes)\n",
    "\n",
    "            # # TEMPORARY to make visdom work\n",
    "            # convc = hsv\n",
    "            # if batch_i % args['visdom_every'] == 0:\n",
    "            #     # visdom_visualize_batch(args['visdom'], img, extent, boundary, distance,\n",
    "            #     #                        logits, bound, dist, hsv, convc, mask, title=\"Val images\")\n",
    "            #     pass\n",
    "\n",
    "    return cumulative_loss, accuracy, f1, mcc, dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from your_dataset_module import PlanetDatasetWithClassesFullPathsMasked\n",
    "#from resuneta.models.resunet_d6_causal_mtskcolor_ddist import ResUNetD6 as ResUNet_d6\n",
    "#from resuneta.models.resunet_d7_causal_mtskcolor_ddist import ResUNet_d7\n",
    "from GitHub import FracTAL_ResUNet\n",
    "\n",
    "# FracTAL_ResUNet_cmtsk, ftnmt_loss_masked\n",
    "# from your_loss_module import tanimoto_dual\n",
    "\n",
    "\n",
    "def run_africa(country, train_names, val_names, test_names,\n",
    "               train_names_label, val_names_label, test_names_label,\n",
    "               trained_model=None,\n",
    "               epochs=100, lr=0.001, lr_decay=None,\n",
    "               model_type='resunet-d6',\n",
    "               n_filters=16, batch_size=8,\n",
    "               depth=5, n_classes=1,\n",
    "               month='janFebMar',\n",
    "               codes_to_keep=[1, 2],\n",
    "               folder_suffix='',\n",
    "               boundary_kernel_size=3,\n",
    "               ctx_name='cpu',\n",
    "               gpu_id=0):\n",
    "\n",
    "    # Set PyTorch device\n",
    "    device = torch.device(\"cuda:0\" if ctx_name == 'gpu' else \"cpu\")\n",
    "\n",
    "    # Set up names of directories and paths for saving\n",
    "    if trained_model is None:\n",
    "        folder_name = model_type + '_' + month + '_nfilter-' + str(n_filters) + \\\n",
    "                      '_depth-' + str(depth) + '_bs-' + str(batch_size) + '_lr-' + str(lr) + folder_suffix\n",
    "        if lr_decay:\n",
    "            folder_name = folder_name + '_lrdecay-' + str(lr_decay)\n",
    "\n",
    "        # Define model\n",
    "        if model_type == 'resunet-d6':\n",
    "            model = ResUNet_d6(n_filters_init=n_filters, n_classes=n_classes)\n",
    "        elif model_type == 'resunet-d7':\n",
    "            model = ResUNet_d7(n_filters_init=n_filters, n_classes=n_classes)\n",
    "        elif model_type == 'fractal-resunet':\n",
    "            model = FracTAL_ResUNet_cmtsk(nfilters_init=n_filters, norm_groups=1, depth=depth, NClasses=n_classes)\n",
    "        model.to(device)\n",
    "\n",
    "    else:\n",
    "        folder_name = model_type + '_' + month + '_nfilter-' + str(n_filters) + \\\n",
    "                      '_bs-' + str(batch_size) + '_lr-' + str(lr) + folder_suffix + '_finetuned'\n",
    "        if model_type == 'resunet-d6':\n",
    "            model = ResUNet_d6(n_filters_init=n_filters, n_classes=n_classes)\n",
    "        elif model_type == 'resunet-d7':\n",
    "            model = ResUNet_d7(n_filters_init=n_filters, n_classes=n_classes)\n",
    "        model.load_state_dict(torch.load(trained_model))\n",
    "        model.to(device)\n",
    "\n",
    "    save_path = os.path.join('./experiments/', country, folder_name)\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_model_name = os.path.join(save_path, \"model.pth\")\n",
    "\n",
    "    # Visdom\n",
    "#     env_name = country + '_' + folder_name\n",
    "#     vis = visdom.Visdom(env=env_name)\n",
    "\n",
    "    # Arguments\n",
    "    args = {\n",
    "        'batch_size': batch_size,\n",
    "        'ctx_name': ctx_name,\n",
    "        'gpu': gpu_id,\n",
    "#         'visdom': vis,\n",
    "        'visdom_every': 20,\n",
    "        'device': device\n",
    "    }\n",
    "\n",
    "    # Define train/val/test splits\n",
    "    train_dataset = PlanetDatasetWithClassesFullPathsMasked(\n",
    "        fold='train',\n",
    "        image_names=train_names,\n",
    "        label_names=train_names_label,\n",
    "        classes=codes_to_keep,\n",
    "        boundary_kernel_size=boundary_kernel_size)\n",
    "    val_dataset = PlanetDatasetWithClassesFullPathsMasked(\n",
    "        fold='val',\n",
    "        image_names=val_names,\n",
    "        label_names=val_names_label,\n",
    "        classes=codes_to_keep,\n",
    "        boundary_kernel_size=boundary_kernel_size)\n",
    "    test_dataset = PlanetDatasetWithClassesFullPathsMasked(\n",
    "        fold='test',\n",
    "        image_names=test_names,\n",
    "        label_names=test_names_label,\n",
    "        classes=codes_to_keep,\n",
    "        boundary_kernel_size=boundary_kernel_size)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    tanimoto_dual = ftnmt_loss_masked(depth=0) # Tanimoto_with_dual_masked()\n",
    "    \n",
    "    # Define loss function\n",
    "    if lr_decay:\n",
    "        schedule = optim.lr_scheduler.ExponentialLR(optimizer, gamma=lr_decay)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Containers for metrics to log\n",
    "    train_metrics = {'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "                     'train_mcc': [], 'train_dice': []}\n",
    "    val_metrics = {'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "                   'val_mcc': [], 'val_dice': []}\n",
    "    best_mcc = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Training set\n",
    "        train_loss, train_accuracy, train_f1, train_mcc, train_dice = train_model(\n",
    "            train_dataloader, model, tanimoto_dual, optimizer, epoch, args)\n",
    "\n",
    "        # Training set metrics\n",
    "        train_loss_avg = train_loss / len(train_dataset)\n",
    "        train_metrics['train_loss'].append(train_loss_avg)\n",
    "        train_metrics['train_acc'].append(train_accuracy)\n",
    "        train_metrics['train_f1'].append(train_f1)\n",
    "        train_metrics['train_mcc'].append(train_mcc)\n",
    "        train_metrics['train_dice'].append(train_dice)\n",
    "\n",
    "        # Validation set\n",
    "        val_loss, val_accuracy, val_f1, val_mcc, val_dice = evaluate_model(\n",
    "            val_dataloader, model, tanimoto_dual, epoch, args)\n",
    "\n",
    "        # Validation set metrics\n",
    "        val_loss_avg = val_loss / len(val_dataset)\n",
    "        val_metrics['val_loss'].append(val_loss_avg)\n",
    "        val_metrics['val_acc'].append(val_accuracy)\n",
    "        val_metrics['val_f1'].append(val_f1)\n",
    "        val_metrics['val_mcc'].append(val_mcc)\n",
    "        val_metrics['val_dice'].append(val_dice)\n",
    "\n",
    "        print(\"Epoch {}:\".format(epoch))\n",
    "        print(\"    Train loss {:0.3f}, accuracy {:0.3f}, F1-score {:0.3f}, MCC: {:0.3f}, Dice: {:0.3f}\".format(\n",
    "            train_loss_avg, train_accuracy, train_f1, train_mcc, train_dice))\n",
    "        print(\"    Val loss {:0.3f}, accuracy {:0.3f}, F1-score {:0.3f}, MCC: {:0.3f}, Dice: {:0.3f}\".format(\n",
    "            val_loss_avg, val_accuracy, val_f1, val_mcc, val_dice))\n",
    "\n",
    "        # Save model based on best MCC metric\n",
    "        if val_mcc > best_mcc:\n",
    "            torch.save(model.state_dict(), save_model_name)\n",
    "            best_mcc = val_mcc\n",
    "\n",
    "        # Save metrics\n",
    "        metrics = pd.concat([pd.DataFrame(train_metrics), pd.DataFrame(val_metrics)], axis=1)\n",
    "        metrics.to_csv(os.path.join(save_path, 'metrics.csv'), index=False)\n",
    "\n",
    "        # Visdom\n",
    "        vis.line(Y=np.stack([train_metrics['train_loss'], val_metrics['val_loss']], axis=1),\n",
    "                 X=np.arange(1, epoch+1), win=\"Loss\",\n",
    "                 opts=dict(legend=['train loss', 'val loss'], markers=False, title=\"Losses\",\n",
    "                           xlabel=\"Epoch\", ylabel=\"Loss\")\n",
    "                )\n",
    "        vis.line(Y=np.stack([train_metrics['train_mcc'], val_metrics['val_mcc']], axis=1),\n",
    "                 X=np.arange(1, epoch+1), win=\"MCC\",\n",
    "                 opts=dict(legend=['train MCC', 'val MCC'], markers=False, title=\"MCC\",\n",
    "                           xlabel=\"Epoch\", ylabel=\"MCC\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "w5WGMn55KpfH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kai/miniforge3/envs/oaf/lib/python3.11/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "32\n",
      "depth:= 0, nfilters: 32, nheads::8, widths::1\n",
      "depth:= 1, nfilters: 64, nheads::16, widths::1\n",
      "depth:= 2, nfilters: 128, nheads::32, widths::1\n",
      "depth:= 3, nfilters: 256, nheads::64, widths::1\n",
      "depth:= 4, nfilters: 512, nheads::128, widths::1\n",
      "depth:= 5, nfilters: 1024, nheads::256, widths::1\n",
      "depth:= 6, nfilters: 512, nheads::256, widths::1\n",
      "depth:= 7, nfilters: 256, nheads::128, widths::1\n",
      "depth:= 8, nfilters: 128, nheads::64, widths::1\n",
      "depth:= 9, nfilters: 64, nheads::32, widths::1\n",
      "depth:= 10, nfilters: 32, nheads::16, widths::1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   0%|          | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   4%|▍         | 1/26 [00:15<06:28, 15.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:   8%|▊         | 2/26 [00:30<05:59, 14.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:  12%|█▏        | 3/26 [00:45<05:43, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:  15%|█▌        | 4/26 [01:00<05:35, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:  15%|█▌        | 4/26 [01:14<06:51, 18.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kai/Desktop/OAF new/France_TrainModel (1).ipynb Cell 16\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m val_names_label \u001b[39m=\u001b[39m all_labels[all_labels[\u001b[39m'\u001b[39m\u001b[39mfold\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabel_path\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m test_names_label \u001b[39m=\u001b[39m all_labels[all_labels[\u001b[39m'\u001b[39m\u001b[39mfold\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlabel_path\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m run_africa(country, train_names, val_names, test_names,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m            train_names_label, val_names_label, test_names_label,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m            trained_model\u001b[39m=\u001b[39;49mtrained_model,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m            epochs\u001b[39m=\u001b[39;49mepochs, lr\u001b[39m=\u001b[39;49mlr, lr_decay\u001b[39m=\u001b[39;49mlr_decay,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m            model_type\u001b[39m=\u001b[39;49mmodel_type, n_filters\u001b[39m=\u001b[39;49mn_filters, depth\u001b[39m=\u001b[39;49mdepth, n_classes\u001b[39m=\u001b[39;49mn_classes,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m            batch_size\u001b[39m=\u001b[39;49mbatch_size, month\u001b[39m=\u001b[39;49mmonth_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m            codes_to_keep\u001b[39m=\u001b[39;49mcodes_to_keep,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m            ctx_name\u001b[39m=\u001b[39;49mctx_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m            gpu_id\u001b[39m=\u001b[39;49mgpu_id,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m            folder_suffix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m_debugging_pytorch_code\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m            boundary_kernel_size\u001b[39m=\u001b[39;49mboundary_kernel_size)\n",
      "\u001b[1;32m/Users/kai/Desktop/OAF new/France_TrainModel (1).ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m \u001b[39m# Training loop\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m     \u001b[39m# Training set\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m     train_loss, train_accuracy, train_f1, train_mcc, train_dice \u001b[39m=\u001b[39m train_model(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m         train_dataloader, model, tanimoto_dual, optimizer, epoch, args)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     \u001b[39m# Training set metrics\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m     train_loss_avg \u001b[39m=\u001b[39m train_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_dataset)\n",
      "\u001b[1;32m/Users/kai/Desktop/OAF new/France_TrainModel (1).ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m loss_distance \u001b[39m=\u001b[39m tanimoto_dual(dist, distance, mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.33\u001b[39m \u001b[39m*\u001b[39m (loss_extent \u001b[39m+\u001b[39m loss_boundary \u001b[39m+\u001b[39m loss_distance)  \u001b[39m# + loss_hsv)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kai/Desktop/OAF%20new/France_TrainModel%20%281%29.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m cumulative_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniforge3/envs/oaf/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/oaf/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the training and evaluation\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ============================ #\n",
    "# user-specified hyperparameters\n",
    "# ============================ #\n",
    "country = 'partial-france'\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "lr_decay = None\n",
    "n_filters = 32\n",
    "depth = 6\n",
    "n_classes = 1\n",
    "batch_size = 8\n",
    "model_type = 'fractal-resunet'  # 'resunet-d6'\n",
    "month_name = '3month-separate'\n",
    "codes_to_keep = list(range(1, 10)) + [11, 14, 15, 16, 17, 18, 19, 21, 24, 25, 26, 28]\n",
    "ctx_name = 'cpu' #'gpu'\n",
    "gpu_id = 0\n",
    "boundary_kernel_size = (2, 2)\n",
    "\n",
    "\n",
    "\n",
    "# trained_model = '../experiments/france/sherrie10k/' + \\\n",
    "#     'resunet-d6_2019_10_class-notreeexceptvines_nfilter-16_bs-8_lr-0.001_1x-8x-downsampled/model.params'\n",
    "trained_model = None\n",
    "# splits_path = '../data/splits/sherrie10k_planetImagery_splits_20x20_4x-downsampled.csv'\n",
    "splits_path = 'sherrie10k_planetImagery_splits_20x20_4x-downsampled.csv' # THIS NEEDS TO BE CREATED\n",
    "splits_df = pd.read_csv(splits_path)\n",
    "splits_df['image_id'] = splits_df['image_id'].astype(str).str.zfill(5)\n",
    "\n",
    "# get all img and labels\n",
    "all_img_names = []\n",
    "all_label_names = []\n",
    "img_dir = './GitHub/FracTAL_ResUNet/data/france/images/'\n",
    "label_dir = './GitHub/FracTAL_ResUNet/data/france/labels/'\n",
    "# subfolders = ['2x_downsample', '3x_downsample']\n",
    "\n",
    "# for subfolder in subfolders:\n",
    "#     label_folder_imgs = sorted(os.listdir(os.path.join(label_dir, subfolder)))\n",
    "for label_name in sorted(os.listdir(label_dir)):\n",
    "    for month in [\"2019_04\", \"2019_07\", \"2019_10\"]:\n",
    "        img_name = label_name.split('.')[0] + '_' + month + '.tif'\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        all_img_names.append(img_path)\n",
    "        label_path = os.path.join(label_dir, label_name)\n",
    "        all_label_names.append(label_path)\n",
    "\n",
    "# split imgs and labels into train/val/test\n",
    "all_images = pd.DataFrame({'img_path': all_img_names})\n",
    "all_images['image_id'] = all_images['img_path'].str.split('/').apply(\n",
    "    lambda x: x[-1]).str.split('.').apply(\n",
    "    lambda x: x[0]).str.split('_').apply(\n",
    "    lambda x: x[0])\n",
    "all_images = all_images.merge(splits_df[['image_id', 'fold']], on='image_id', how='left')\n",
    "train_names = all_images[all_images['fold'] == 'train']['img_path'].values\n",
    "val_names = all_images[all_images['fold'] == 'val']['img_path'].values\n",
    "test_names = all_images[all_images['fold'] == 'test']['img_path'].values\n",
    "\n",
    "all_labels = pd.DataFrame({'label_path': all_label_names})\n",
    "all_labels['image_id'] = all_labels['label_path'].str.split('/').apply(\n",
    "    lambda x: x[-1]).str.split('.').apply(\n",
    "    lambda x: x[0])\n",
    "all_labels = all_labels.merge(splits_df[['image_id', 'fold']], on='image_id', how='left')\n",
    "train_names_label = all_labels[all_labels['fold'] == 'train']['label_path'].values\n",
    "val_names_label = all_labels[all_labels['fold'] == 'val']['label_path'].values\n",
    "test_names_label = all_labels[all_labels['fold'] == 'test']['label_path'].values\n",
    "\n",
    "run_africa(country, train_names, val_names, test_names,\n",
    "           train_names_label, val_names_label, test_names_label,\n",
    "           trained_model=trained_model,\n",
    "           epochs=epochs, lr=lr, lr_decay=lr_decay,\n",
    "           model_type=model_type, n_filters=n_filters, depth=depth, n_classes=n_classes,\n",
    "           batch_size=batch_size, month=month_name,\n",
    "           codes_to_keep=codes_to_keep,\n",
    "           ctx_name=ctx_name,\n",
    "           gpu_id=gpu_id,\n",
    "           folder_suffix='_debugging_pytorch_code',\n",
    "           boundary_kernel_size=boundary_kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fRKfWemNLzq"
   },
   "source": [
    "# Old code dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HBRefOKNNFC"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Define data transformations\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# # Create custom datasets\n",
    "# train_dataset = PlanetDatasetWithClassesFullPathsMasked(train_names, train_names_label, codes_to_keep, transform)\n",
    "# val_dataset = PlanetDatasetWithClassesFullPathsMasked(val_names, val_names_label, codes_to_keep, transform)\n",
    "# test_dataset = PlanetDatasetWithClassesFullPathsMasked(test_names, test_names_label, codes_to_keep, transform)\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# # Define your loss function and optimizer\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# # Training loop (you need to implement the training loop)\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     # Print average loss per epoch\n",
    "#     print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "# # Validation loop (you need to implement the validation loop)\n",
    "# model.eval()\n",
    "# running_loss = 0.0\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in val_loader:\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "# # Print validation loss\n",
    "# print(f'Validation Loss: {running_loss / len(val_loader)}')\n",
    "\n",
    "# # Test loop (you need to implement the test loop)\n",
    "# model.eval()\n",
    "# all_preds = []\n",
    "# all_labels = []\n",
    "# with torch.no_grad():\n",
    "#     for inputs, labels in test_loader:\n",
    "#         outputs = model(inputs)\n",
    "#         # Process your model's predictions here\n",
    "#         preds = torch.argmax(outputs, dim=1)\n",
    "#         all_preds.append(preds)\n",
    "#         all_labels.append(labels)\n",
    "\n",
    "# # Calculate evaluation metrics (you need to implement this)\n",
    "# all_preds = torch.cat(all_preds)\n",
    "# all_labels = torch.cat(all_labels)\n",
    "# mcc = matthews_corrcoef(all_labels, all_preds)\n",
    "# f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "\n",
    "# # Print evaluation metrics\n",
    "# print(f'MCC: {mcc}, F1: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDrIiSEUJo5y"
   },
   "outputs": [],
   "source": [
    "\n",
    "# def train_model(train_dataloader, model, tanimoto_dual, optimizer, epoch, args):\n",
    "#     model.train()\n",
    "#     cumulative_loss = 0\n",
    "#     accuracy = 0\n",
    "#     f1 = 0\n",
    "#     mcc = 0\n",
    "#     dice = 0\n",
    "\n",
    "#     for batch_i, (img, extent, boundary, distance, hsv, mask) in enumerate(\n",
    "#         tqdm(train_dataloader, desc='Training epoch {}'.format(epoch))):\n",
    "\n",
    "#         img, extent, boundary, distance, hsv, mask = img.to(args['device']), extent.to(args['device']), boundary.to(args['device']), distance.to(args['device']), hsv.to(args['device']), mask.to(args['device'])\n",
    "#         nonmask = torch.ones(extent.shape).to(args['device'])\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         logits, bound, dist = model(img)\n",
    "\n",
    "#         loss_extent = torch.sum(tanimoto_dual(logits, extent, mask))\n",
    "#         loss_boundary = torch.sum(tanimoto_dual(bound, boundary, mask))\n",
    "#         loss_distance = torch.sum(tanimoto_dual(dist, distance, mask))\n",
    "\n",
    "#         loss = 0.33 * (loss_extent + loss_boundary + loss_distance)\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         cumulative_loss += loss.item()\n",
    "\n",
    "#         logits_reshaped = logits.view(logits.shape[0], -1)\n",
    "#         extent_reshaped = extent.view(extent.shape[0], -1)\n",
    "#         mask_reshaped = mask.view(mask.shape[0], -1)\n",
    "\n",
    "#         nonmask_idx = (mask_reshaped != 0).nonzero()\n",
    "#         logits_masked = logits_reshaped[nonmask_idx]\n",
    "\n",
    "#         extent_masked = extent_reshaped[nonmask_idx]\n",
    "\n",
    "#         extent_predicted_classes = torch.ceil(logits_masked - 0.5)\n",
    "#         accuracy += (extent_predicted_classes == extent_masked).sum().item()\n",
    "\n",
    "#         probabilities = torch.stack([1 - logits_masked, logits_masked], dim=1)\n",
    "#         f1 += f1_score(extent_masked.cpu().numpy(), extent_predicted_classes.cpu().numpy(), average='macro')\n",
    "#         mcc += matthews_corrcoef(extent_masked.cpu().numpy(), extent_predicted_classes.cpu().numpy())\n",
    "#         dice += dice_coef(extent_masked, extent_predicted_classes)\n",
    "\n",
    "#     return cumulative_loss, accuracy, f1, mcc, dice\n",
    "\n",
    "# def evaluate_model(val_dataloader, model, tanimoto_dual, epoch, args):\n",
    "#     model.eval()\n",
    "#     cumulative_loss = 0\n",
    "#     accuracy = 0\n",
    "#     f1 = 0\n",
    "#     mcc = 0\n",
    "#     dice = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_i, (img, extent, boundary, distance, hsv, mask) in enumerate(\n",
    "#             tqdm(val_dataloader, desc='Validation epoch {}'.format(epoch))):\n",
    "\n",
    "#             img, extent, boundary, distance, hsv, mask = img.to(args['device']), extent.to(args['device']), boundary.to(args['device']), distance.to(args['device']), hsv.to(args['device']), mask.to(args['device'])\n",
    "#             nonmask = torch.ones(extent.shape).to(args['device'])\n",
    "\n",
    "#             logits, bound, dist = model(img)\n",
    "\n",
    "#             loss_extent = torch.sum(tanimoto_dual(logits, extent, mask))\n",
    "#             loss_boundary = torch.sum(tanimoto_dual(bound, boundary, mask))\n",
    "#             loss_distance = torch.sum(tanimoto_dual(dist, distance, mask))\n",
    "\n",
    "#             loss = 0.33 * (loss_extent + loss_boundary + loss_distance)\n",
    "#             cumulative_loss += loss.item()\n",
    "\n",
    "#             logits_reshaped = logits.view(logits.shape[0], -1)\n",
    "#             extent_reshaped = extent.view(extent.shape[0], -1)\n",
    "#             mask_reshaped = mask.view(mask.shape[0], -1)\n",
    "\n",
    "#             nonmask_idx = (mask_reshaped != 0).nonzero()\n",
    "#             logits_masked = logits_reshaped[nonmask_idx]\n",
    "#             extent_masked = extent_reshaped[nonmask_idx]\n",
    "\n",
    "#             extent_predicted_classes = torch.ceil(logits_masked - 0.5)\n",
    "#             accuracy += (extent_predicted_classes == extent_masked).sum().item()\n",
    "\n",
    "#             probabilities = torch.stack([1 - logits_masked, logits_masked], dim=1)\n",
    "#             f1 += f1_score(extent_masked.cpu().numpy(), extent_predicted_classes.cpu().numpy(), average='macro')\n",
    "#             mcc += matthews_corrcoef(extent_masked.cpu().numpy(), extent_predicted_classes.cpu().numpy())\n",
    "#             dice += dice_coef(extent_masked, extent_predicted_classes)\n",
    "\n",
    "#     return cumulative_loss, accuracy, f1, mcc, dice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeKaMc5LZbZM"
   },
   "source": [
    "SHERRIE MXNET VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "On6TSipw-6Op"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# import visdom\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import autograd\n",
    "from mxnet import image\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../resuneta/src')\n",
    "sys.path.append('../../decode/FracTAL_ResUNet/models/semanticsegmentation')\n",
    "sys.path.append('../../decode/FracTAL_ResUNet/nn/loss')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../MXNet-ResUNeta/')\n",
    "\n",
    "from bound_dist import get_distance, get_boundary\n",
    "from FracTAL_ResUNet import FracTAL_ResUNet_cmtsk\n",
    "from ftnmt_loss import ftnmt_loss_masked\n",
    "from datasets import *\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def dice_coef(x, y):\n",
    "    if type(x).__module__ == 'numpy':\n",
    "        intersection = np.logical_and(x, y)\n",
    "        return 2. * np.sum(intersection) / (np.sum(x) + np.sum(y))\n",
    "    else:\n",
    "        intersection = mx.ndarray.op.broadcast_logical_and(x, y)\n",
    "        return 2. * mx.nd.sum(intersection) / (mx.nd.sum(x) + mx.nd.sum(y))\n",
    "def visdom_visualize_batch(vis, img, extent, boundary, distance,\n",
    "                           extent_pred, boundary_pred, distance_pred,\n",
    "                           hsv, hsv_pred, mask, title=\"Train images\"):\n",
    "\n",
    "    img, extent, boundary, distance = img.asnumpy(), extent.asnumpy(), boundary.asnumpy(), distance.asnumpy()\n",
    "    extent_pred, boundary_pred = extent_pred.asnumpy(), boundary_pred.asnumpy()\n",
    "    distance_pred, hsv, hsv_pred = distance_pred.asnumpy(), hsv.asnumpy(), hsv_pred.asnumpy()\n",
    "    mask = mask.asnumpy()\n",
    "\n",
    "    # put everything in one window\n",
    "    batch_size, nchannels, nrows, ncols = img.shape\n",
    "    padding = 10\n",
    "    items = [img, hsv, hsv_pred, extent, extent_pred,\n",
    "             boundary, boundary_pred, distance, distance_pred,\n",
    "             mask]\n",
    "    result = np.zeros((3, len(items)*nrows + (len(items)-1)*padding, batch_size*ncols + (batch_size-1)*padding))\n",
    "\n",
    "    for j, item in enumerate(items):\n",
    "\n",
    "        if item.shape[1] == 1:\n",
    "            item = np.tile(item, (1,3,1,1)) * 255.\n",
    "\n",
    "        if j == 1 or j == 2: # convert HSV to RGB\n",
    "            item = np.moveaxis(item, 1, -1) * 255.\n",
    "            for i in range(batch_size):\n",
    "                item[i] = cv2.cvtColor(item[i].astype(np.uint8), cv2.COLOR_HSV2RGB)\n",
    "            item = np.moveaxis(item, -1, 1)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            result[:, j*(nrows+padding):(j+1)*nrows+j*padding, i*(ncols+padding):(i+1)*ncols+i*padding] = item[i]\n",
    "    vis.images(result, nrow=1, win=title, opts={'title': title})\n",
    "def train_model(train_dataloader, model, tanimoto_dual, trainer, epoch, args):\n",
    "\n",
    "    # initialize metrics\n",
    "    cumulative_loss = 0\n",
    "    accuracy = mx.metric.Accuracy()\n",
    "    f1 = mx.metric.F1()\n",
    "    mcc = mx.metric.MCC()\n",
    "    dice = mx.metric.CustomMetric(feval=dice_coef, name=\"Dice\")\n",
    "    if args['ctx_name'] == 'cpu':\n",
    "        ctx = mx.cpu()\n",
    "    else:\n",
    "        ctx = mx.gpu(args['gpu'])\n",
    "\n",
    "    # training set\n",
    "    for batch_i, (img, extent, boundary, distance, hsv, mask) in enumerate(\n",
    "        tqdm(train_dataloader, desc='Training epoch {}'.format(epoch))):\n",
    "\n",
    "        with autograd.record():\n",
    "\n",
    "            img = img.as_in_context(ctx)\n",
    "            extent = extent.as_in_context(ctx)\n",
    "            boundary = boundary.as_in_context(ctx)\n",
    "            distance = distance.as_in_context(ctx)\n",
    "            hsv = hsv.as_in_context(ctx)\n",
    "            mask = mask.as_in_context(ctx)\n",
    "            nonmask = mx.nd.ones(extent.shape).as_in_context(ctx)\n",
    "\n",
    "            # logits, bound, dist, convc = model(img)\n",
    "            logits, bound, dist = model(img)\n",
    "\n",
    "            # multi-task loss\n",
    "            # TODO: wrap this in a custom loss function / class\n",
    "            loss_extent = mx.nd.sum(tanimoto_dual(logits, extent, mask))\n",
    "            loss_boundary = mx.nd.sum(tanimoto_dual(bound, boundary, mask))\n",
    "            loss_distance = mx.nd.sum(tanimoto_dual(dist, distance, mask))\n",
    "\n",
    "            loss = 0.33 * (loss_extent + loss_boundary + loss_distance) # + loss_hsv)\n",
    "\n",
    "        loss.backward()\n",
    "        trainer.step(args['batch_size'])\n",
    "        cumulative_loss += mx.nd.sum(loss).asscalar()\n",
    "\n",
    "        logits_reshaped = logits.reshape((logits.shape[0], -1))\n",
    "        extent_reshaped = extent.reshape((extent.shape[0], -1))\n",
    "        mask_reshaped = mask.reshape((mask.shape[0], -1))\n",
    "\n",
    "        nonmask_idx = mx.np.nonzero(mask_reshaped.as_np_ndarray())\n",
    "        nonmask_idx = mx.np.stack(nonmask_idx).as_nd_ndarray().as_in_context(ctx)\n",
    "        logits_masked = mx.nd.gather_nd(logits_reshaped, nonmask_idx)\n",
    "        extent_masked = mx.nd.gather_nd(extent_reshaped, nonmask_idx)\n",
    "\n",
    "        # accuracy\n",
    "        extent_predicted_classes = mx.nd.ceil(logits_masked - 0.5)\n",
    "        accuracy.update(extent_masked, extent_predicted_classes)\n",
    "\n",
    "        # f1 score\n",
    "        probabilities = mx.nd.stack(1 - logits_masked, logits_masked, axis=1)\n",
    "        f1.update(extent_masked, probabilities)\n",
    "\n",
    "        # MCC metric\n",
    "        mcc.update(extent_masked, probabilities)\n",
    "\n",
    "        # Dice score\n",
    "        dice.update(extent_masked, extent_predicted_classes)\n",
    "\n",
    "        # TEMPORARY to make visdom work\n",
    "        convc = hsv\n",
    "        if batch_i % args['visdom_every'] == 0:\n",
    "            visdom_visualize_batch(args['visdom'], img, extent, boundary, distance,\n",
    "                                   logits, bound, dist, hsv, convc, mask)\n",
    "\n",
    "    return cumulative_loss, accuracy, f1, mcc, dice\n",
    "def evaluate_model(val_dataloader, model, tanimoto_dual, epoch, args):\n",
    "\n",
    "    # initialize metrics\n",
    "    cumulative_loss = 0\n",
    "    accuracy = mx.metric.Accuracy()\n",
    "    f1 = mx.metric.F1()\n",
    "    mcc = mx.metric.MCC()\n",
    "    dice = mx.metric.CustomMetric(feval=dice_coef, name=\"Dice\")\n",
    "    if args['ctx_name'] == 'cpu':\n",
    "        ctx = mx.cpu()\n",
    "    else:\n",
    "        ctx = mx.gpu(args['gpu'])\n",
    "\n",
    "    # validation set\n",
    "    for batch_i, (img, extent, boundary, distance, hsv, mask) in enumerate(\n",
    "        tqdm(val_dataloader, desc='Validation epoch {}'.format(epoch))):\n",
    "\n",
    "        img = img.as_in_context(ctx)\n",
    "        extent = extent.as_in_context(ctx)\n",
    "        boundary = boundary.as_in_context(ctx)\n",
    "        distance = distance.as_in_context(ctx)\n",
    "        hsv = hsv.as_in_context(ctx)\n",
    "        mask = mask.as_in_context(ctx)\n",
    "        nonmask = mx.nd.ones(extent.shape).as_in_context(ctx)\n",
    "\n",
    "        # logits, bound, dist, convc = model(img)\n",
    "        logits, bound, dist = model(img)\n",
    "\n",
    "        # multi-task loss\n",
    "        # TODO: wrap this in a custom loss function / class\n",
    "        loss_extent = mx.nd.sum(tanimoto_dual(logits, extent, mask))\n",
    "        loss_boundary = mx.nd.sum(tanimoto_dual(bound, boundary, mask))\n",
    "        loss_distance = mx.nd.sum(tanimoto_dual(dist, distance, mask))\n",
    "\n",
    "        loss = 0.33 * (loss_extent + loss_boundary + loss_distance) # + loss_hsv)\n",
    "\n",
    "        # update metrics based on every batch\n",
    "        cumulative_loss += mx.nd.sum(loss).asscalar()\n",
    "\n",
    "        # update metrics based on every batch\n",
    "        # mask out unlabeled pixels\n",
    "        logits_reshaped = logits.reshape((logits.shape[0], -1))\n",
    "        extent_reshaped = extent.reshape((extent.shape[0], -1))\n",
    "        mask_reshaped = mask.reshape((mask.shape[0], -1))\n",
    "\n",
    "        nonmask_idx = mx.np.nonzero(mask_reshaped.as_np_ndarray())\n",
    "        nonmask_idx = mx.np.stack(nonmask_idx).as_nd_ndarray().as_in_context(ctx)\n",
    "        logits_masked = mx.nd.gather_nd(logits_reshaped, nonmask_idx)\n",
    "        extent_masked = mx.nd.gather_nd(extent_reshaped, nonmask_idx)\n",
    "\n",
    "        # accuracy\n",
    "        extent_predicted_classes = mx.nd.ceil(logits_masked - 0.5)\n",
    "        accuracy.update(extent_masked, extent_predicted_classes)\n",
    "\n",
    "        # f1 score\n",
    "        probabilities = mx.nd.stack(1 - logits_masked, logits_masked, axis=1)\n",
    "        f1.update(extent_masked, probabilities)\n",
    "\n",
    "        # MCC metric\n",
    "        mcc.update(extent_masked, probabilities)\n",
    "\n",
    "        # Dice score\n",
    "        dice.update(extent_masked, extent_predicted_classes)\n",
    "\n",
    "        # TEMPORARY to make visdom work\n",
    "        convc = hsv\n",
    "        if batch_i % args['visdom_every'] == 0:\n",
    "            visdom_visualize_batch(args['visdom'], img, extent, boundary, distance,\n",
    "                                   logits, bound, dist, hsv, convc, mask, title=\"Val images\")\n",
    "\n",
    "    return cumulative_loss, accuracy, f1, mcc, dice\n",
    "\n",
    "def run_africa(country, train_names, val_names, test_names,\n",
    "               train_names_label, val_names_label, test_names_label,\n",
    "               trained_model=None,\n",
    "               epochs=100, lr=0.001, lr_decay=None,\n",
    "               model_type='resunet-d6',\n",
    "               n_filters=16, batch_size=8,\n",
    "               depth=5, n_classes=1,\n",
    "               month='janFebMar',\n",
    "               codes_to_keep=[1, 2],\n",
    "               folder_suffix='',\n",
    "               boundary_kernel_size=3,\n",
    "               ctx_name='cpu',\n",
    "               gpu_id=0):\n",
    "\n",
    "    # Set MXNet ctx\n",
    "    if ctx_name == 'cpu':\n",
    "        ctx = mx.cpu()\n",
    "    elif ctx_name == 'gpu':\n",
    "        ctx = mx.gpu(gpu_id)\n",
    "\n",
    "    # Set up names of directories and paths for saving\n",
    "    if trained_model is None:\n",
    "        folder_name = model_type+'_'+month+'_nfilter-'+str(n_filters)+ \\\n",
    "                      '_depth-'+str(depth)+'_bs-'+str(batch_size)+'_lr-'+str(lr)+folder_suffix\n",
    "        if lr_decay:\n",
    "            folder_name = folder_name + '_lrdecay-'+str(lr_decay)\n",
    "\n",
    "        # define model\n",
    "        if model_type == 'resunet-d6':\n",
    "            model = ResUNet_d6(_nfilters_init=n_filters, _NClasses=n_classes)\n",
    "        elif model_type == 'resunet-d7':\n",
    "            model = ResUNet_d7(_nfilters_init=n_filters, _NClasses=n_classes)\n",
    "        elif model_type == 'fractal-resunet':\n",
    "            model = FracTAL_ResUNet_cmtsk(nfilters_init=n_filters, depth=depth, NClasses=n_classes)\n",
    "        model.initialize()\n",
    "        model.hybridize()\n",
    "        model.collect_params().reset_ctx(ctx)\n",
    "\n",
    "    else:\n",
    "        folder_name = model_type+'_'+month+'_nfilter-'+str(n_filters)+ \\\n",
    "                      '_bs-'+str(batch_size)+'_lr-'+str(lr)+folder_suffix+'_finetuned'\n",
    "        if model_type == 'resunet-d6':\n",
    "            model = ResUNet_d6(_nfilters_init=n_filters, _NClasses=n_classes)\n",
    "        elif model_type == 'resunet-d7':\n",
    "            model = ResUNet_d7(_nfilters_init=n_filters, _NClasses=n_classes)\n",
    "        model.load_parameters(trained_model, ctx=ctx)\n",
    "\n",
    "    save_path = os.path.join('../experiments/', country, folder_name)\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    save_model_name = os.path.join(save_path, \"model.params\")\n",
    "\n",
    "#     # Visdom\n",
    "#     env_name = country + '_' + folder_name\n",
    "#     vis = visdom.Visdom(port=8097, env=env_name)\n",
    "\n",
    "    # Arguments\n",
    "    args = {}\n",
    "    args['batch_size'] = batch_size\n",
    "    args['ctx_name'] = ctx_name\n",
    "    args['gpu'] = gpu_id\n",
    "    args['visdom'] = vis\n",
    "    args['visdom_every'] = 20\n",
    "\n",
    "    # Define train/val/test splits\n",
    "    train_dataset = PlanetDatasetWithClassesFullPathsMasked(\n",
    "        fold='train',\n",
    "        image_names=train_names,\n",
    "        label_names=train_names_label,\n",
    "        classes=codes_to_keep,\n",
    "        boundary_kernel_size=boundary_kernel_size)\n",
    "    val_dataset = PlanetDatasetWithClassesFullPathsMasked(\n",
    "        fold='val',\n",
    "        image_names=val_names,\n",
    "        label_names=val_names_label,\n",
    "        classes=codes_to_keep,\n",
    "        boundary_kernel_size=boundary_kernel_size)\n",
    "    test_dataset = PlanetDatasetWithClassesFullPathsMasked(\n",
    "        fold='test',\n",
    "        image_names=test_names,\n",
    "        label_names=test_names_label,\n",
    "        classes=codes_to_keep,\n",
    "        boundary_kernel_size=boundary_kernel_size)\n",
    "\n",
    "    train_dataloader = gluon.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = gluon.data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = gluon.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # define loss function\n",
    "    tanimoto_dual = ftnmt_loss_masked(depth=0) # Tanimoto_with_dual_masked()\n",
    "\n",
    "    if lr_decay:\n",
    "        schedule = mx.lr_scheduler.FactorScheduler(step=1, factor=lr_decay)\n",
    "        adam_optimizer = mx.optimizer.Adam(learning_rate=lr, lr_scheduler=schedule)\n",
    "    else:\n",
    "        adam_optimizer = mx.optimizer.Adam(learning_rate=lr)\n",
    "    trainer = gluon.Trainer(model.collect_params(), optimizer=adam_optimizer)\n",
    "\n",
    "    # containers for metrics to log\n",
    "    train_metrics = {'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "                     'train_mcc': [], 'train_dice': []}\n",
    "    val_metrics = {'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "                   'val_mcc': [], 'val_dice': []}\n",
    "    best_mcc = 0.0\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        # training set\n",
    "        train_loss, train_accuracy, train_f1, train_mcc, train_dice = train_model(\n",
    "            train_dataloader, model, tanimoto_dual, trainer, epoch, args)\n",
    "\n",
    "        # training set metrics\n",
    "        train_loss_avg = train_loss / len(train_dataset)\n",
    "        train_metrics['train_loss'].append(train_loss_avg)\n",
    "        train_metrics['train_acc'].append(train_accuracy.get()[1])\n",
    "        train_metrics['train_f1'].append(train_f1.get()[1])\n",
    "        train_metrics['train_mcc'].append(train_mcc.get()[1])\n",
    "        train_metrics['train_dice'].append(train_dice.get()[1])\n",
    "\n",
    "        # validation set\n",
    "        val_loss, val_accuracy, val_f1, val_mcc, val_dice = evaluate_model(\n",
    "            val_dataloader, model, tanimoto_dual, epoch, args)\n",
    "\n",
    "        # validation set metrics\n",
    "        val_loss_avg = val_loss / len(val_dataset)\n",
    "        val_metrics['val_loss'].append(val_loss_avg)\n",
    "        val_metrics['val_acc'].append(val_accuracy.get()[1])\n",
    "        val_metrics['val_f1'].append(val_f1.get()[1])\n",
    "        val_metrics['val_mcc'].append(val_mcc.get()[1])\n",
    "        val_metrics['val_dice'].append(val_dice.get()[1])\n",
    "\n",
    "        print(\"Epoch {}:\".format(epoch))\n",
    "        print(\"    Train loss {:0.3f}, accuracy {:0.3f}, F1-score {:0.3f}, MCC: {:0.3f}, Dice: {:0.3f}\".format(\n",
    "            train_loss_avg, train_accuracy.get()[1], train_f1.get()[1], train_mcc.get()[1], train_dice.get()[1]))\n",
    "        print(\"    Val loss {:0.3f}, accuracy {:0.3f}, F1-score {:0.3f}, MCC: {:0.3f}, Dice: {:0.3f}\".format(\n",
    "            val_loss_avg, val_accuracy.get()[1], val_f1.get()[1], val_mcc.get()[1], val_dice.get()[1]))\n",
    "\n",
    "        # save model based on best MCC metric\n",
    "        if val_mcc.get()[1] > best_mcc:\n",
    "            model.save_parameters(save_model_name)\n",
    "            best_mcc = val_mcc.get()[1]\n",
    "\n",
    "        # save metrics\n",
    "        metrics = pd.concat([pd.DataFrame(train_metrics), pd.DataFrame(val_metrics)], axis=1)\n",
    "        metrics.to_csv(os.path.join(save_path, 'metrics.csv'), index=False)\n",
    "\n",
    "        # visdom\n",
    "        vis.line(Y=np.stack([train_metrics['train_loss'], val_metrics['val_loss']], axis=1),\n",
    "                 X=np.arange(1, epoch+1), win=\"Loss\",\n",
    "                 opts=dict(legend=['train loss', 'val loss'], markers=False, title=\"Losses\",\n",
    "                           xlabel=\"Epoch\", ylabel=\"Loss\")\n",
    "                )\n",
    "        vis.line(Y=np.stack([train_metrics['train_mcc'], val_metrics['val_mcc']], axis=1),\n",
    "                 X=np.arange(1, epoch+1), win=\"MCC\",\n",
    "                 opts=dict(legend=['train MCC', 'val MCC'], markers=False, title=\"MCC\",\n",
    "                           xlabel=\"Epoch\", ylabel=\"MCC\")\n",
    "                )\n",
    "# ============================ #\n",
    "# user-specified hyperparameters\n",
    "# ============================ #\n",
    "country = 'partial-france'\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "lr_decay = None\n",
    "n_filters = 32\n",
    "depth = 6\n",
    "n_classes = 1\n",
    "batch_size = 8\n",
    "model_type = 'fractal-resunet' # 'resunet-d6'\n",
    "month_name = '3month-separate'\n",
    "codes_to_keep = list(range(1,10)) + [11,14,15,16,17,18,19,21,24,25,26,28]\n",
    "ctx_name = 'gpu'\n",
    "gpu_id = 2\n",
    "boundary_kernel_size = (2,2)\n",
    "\n",
    "# trained_model = '../experiments/france/sherrie10k/' + \\\n",
    "#     'resunet-d6_2019_10_class-notreeexceptvines_nfilter-16_bs-8_lr-0.001_1x-8x-downsampled/model.params'\n",
    "trained_model = None\n",
    "splits_path = '../data/splits/sherrie10k_planetImagery_splits_20x20_4x-downsampled.csv'\n",
    "splits_df = pd.read_csv(splits_path)\n",
    "splits_df['image_id'] = splits_df['image_id'].astype(str).str.zfill(5)\n",
    "\n",
    "# get all img and labels\n",
    "all_img_names = []\n",
    "all_label_names = []\n",
    "img_dir = '../data/planet/france/sherrie10k/monthly_mosaics_renamed_clipped_merged/1250px/'\n",
    "label_dir = '../data/planet/france/sherrie10k/extent_labels/1250px/'\n",
    "subfolders = ['2x_downsample', '3x_downsample']\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    label_folder_imgs = sorted(os.listdir(os.path.join(label_dir, subfolder)))\n",
    "    for month in ['2019_04', '2019_07', '2019_10']:\n",
    "        for label_name in label_folder_imgs:\n",
    "            img_name = label_name.split('.')[0] + '_' + month + '.tif'\n",
    "            img_path = os.path.join(img_dir, subfolder, month, img_name)\n",
    "            all_img_names.append(img_path)\n",
    "            label_path = os.path.join(label_dir, subfolder, label_name)\n",
    "            all_label_names.append(label_path)\n",
    "\n",
    "# split imgs and labels into train/val/test\n",
    "all_images = pd.DataFrame({'img_path': all_img_names})\n",
    "all_images['image_id'] = all_images['img_path'].str.split('/').apply(\n",
    "    lambda x: x[-1]).str.split('.').apply(\n",
    "    lambda x: x[0]).str.split('_').apply(\n",
    "    lambda x: x[0])\n",
    "all_images = all_images.merge(splits_df[['image_id', 'fold']], on='image_id', how='left')\n",
    "train_names = all_images[all_images['fold'] == 'train']['img_path'].values\n",
    "val_names = all_images[all_images['fold'] == 'val']['img_path'].values\n",
    "test_names = all_images[all_images['fold'] == 'test']['img_path'].values\n",
    "\n",
    "all_labels = pd.DataFrame({'label_path': all_label_names})\n",
    "all_labels['image_id'] = all_labels['label_path'].str.split('/').apply(\n",
    "    lambda x: x[-1]).str.split('.').apply(\n",
    "    lambda x: x[0])\n",
    "all_labels = all_labels.merge(splits_df[['image_id', 'fold']], on='image_id', how='left')\n",
    "train_names_label = all_labels[all_labels['fold'] == 'train']['label_path'].values\n",
    "val_names_label = all_labels[all_labels['fold'] == 'val']['label_path'].values\n",
    "test_names_label = all_labels[all_labels['fold'] == 'test']['label_path'].values\n",
    "\n",
    "# ============================ #\n",
    "\n",
    "run_africa(country, train_names, val_names, test_names,\n",
    "           train_names_label, val_names_label, test_names_label,\n",
    "           trained_model=trained_model,\n",
    "           epochs=epochs, lr=lr, lr_decay=lr_decay,\n",
    "           model_type=model_type, n_filters=n_filters, depth=depth, n_classes=n_classes,\n",
    "           batch_size=batch_size, month=month_name,\n",
    "           codes_to_keep=codes_to_keep,\n",
    "           ctx_name=ctx_name,\n",
    "           gpu_id=gpu_id,\n",
    "           folder_suffix='_2x-3x-downsampled_allfields_n6759',\n",
    "           boundary_kernel_size=boundary_kernel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fiJccSBdMVK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
